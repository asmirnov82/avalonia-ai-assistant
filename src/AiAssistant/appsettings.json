{
    "InferenceParams": {
        "SystemInstructions": "You're an intelligent, concise coding assistant. Wrap code in ``` for readability. Don't repeat yourself. Use best practice and good coding standards.",
        "Temperature": "0.5",
        "PresencePenalty": "0",
        "FrequencyPenalty": "0"
    },

    //Phi 3 Mini Instruct
    /*
    "ModelParams": {
        "ModelName": "Phi-3-mini-4k-instruct-Q4_K_M.gguf",
        "ModelPath": "C:\\ML\\Models\\Phi-3-mini-4k\\",
        "GpuLayerCount": "33",
        "TotalLayerCount": "33",
        "ContextSize": "4096"
    }
    */

    //Phi 3 Medium
    /*
    "ModelParams": {
        "ModelName": "Phi-3-medium-4k-instruct-Q4_K_M.gguf",
        "ModelPath": "C:\\ML\\Models\\Phi-3-medium-4k\\",
        "GpuLayerCount": "18",
        "TotalLayerCount": "41",
        "ContextSize": "4096"
    }
    */

    //Lama3 8B Instruct
    "ModelParams": {
        "ModelName": "llama-3-8B-Instruct.Q4_K_M.gguf",
        "ModelPath": "C:\\ML\\Models\\LLaMA\\",
        "GpuLayerCount": "24",
        "TotalLayerCount": "33",
        "ContextSize": "8192"
    }
}
